<html>
<head>
<title>FilghtPricePrediction.ipynb</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #bcbec4;}
.s1 { color: #cf8e6d;}
.s2 { color: #bcbec4;}
.s3 { color: #6aab73;}
.s4 { color: #2aacb8;}
.ls0 { height: 1px; border-width: 0; color: #43454a; background-color:#43454a}
.ln { color: #4b5059; font-weight: normal; font-style: normal; }
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
FilghtPricePrediction.ipynb</font>
</center></td></tr></table>
<pre><a name="l1"><span class="ln">1    </span></a><span class="s0">#%% md 
<a name="l2"><span class="ln">2    </span></a># **Flight Price Prediction Project** 
<a name="l3"><span class="ln">3    </span></a> 
<a name="l4"><span class="ln">4    </span></a>Professor - Mohammad Mahdavi 
<a name="l5"><span class="ln">5    </span></a>Module - M606 Machine Learning 
<a name="l6"><span class="ln">6    </span></a> 
<a name="l7"><span class="ln">7    </span></a>### Introduction: 
<a name="l8"><span class="ln">8    </span></a> 
<a name="l9"><span class="ln">9    </span></a>Flight ticket prices change a lot depending on the time, airline, number of stops, and many other factors, so it becomes difficult for people to know the right time to book a ticket. At the same time, airlines also benefit if they know when prices might go high or low, so they can plan offers and discounts. 
<a name="l10"><span class="ln">10   </span></a> 
<a name="l11"><span class="ln">11   </span></a>In this project, I worked on predicting flight fares using machine learning. For this, I used the Kaggle Flight Price Prediction dataset which contains details like airline name, travel date, route, duration, stops, and final ticket price. Using this data, I built a model that can predict the flight price based on the given information. As a data Scientist i will try ti train best model to make good prediction with more accuracy. 
<a name="l12"><span class="ln">12   </span></a> 
<a name="l13"><span class="ln">13   </span></a>To perform the prediction, I used three machine learning models: 
<a name="l14"><span class="ln">14   </span></a> 
<a name="l15"><span class="ln">15   </span></a>**Gradient Boosting Regressor 
<a name="l16"><span class="ln">16   </span></a> 
<a name="l17"><span class="ln">17   </span></a>XGBoost 
<a name="l18"><span class="ln">18   </span></a> 
<a name="l19"><span class="ln">19   </span></a>Random Forest Regressor** 
<a name="l20"><span class="ln">20   </span></a> 
<a name="l21"><span class="ln">21   </span></a>I have then compared them to see which one gives the best price prediction result. 
<a name="l22"><span class="ln">22   </span></a> 
<a name="l23"><span class="ln">23   </span></a> 
<a name="l24"><span class="ln">24   </span></a>**Please refer to below link:** 
<a name="l25"><span class="ln">25   </span></a> 
<a name="l26"><span class="ln">26   </span></a># **Important Links  :** 
<a name="l27"><span class="ln">27   </span></a> 
<a name="l28"><span class="ln">28   </span></a>GitHub Project Link - https://github.com/AniketSonu/FlightPricePrediction 
<a name="l29"><span class="ln">29   </span></a> 
<a name="l30"><span class="ln">30   </span></a>DataSet - https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction?select=Clean_Dataset.csv 
<a name="l31"><span class="ln">31   </span></a> 
<a name="l32"><span class="ln">32   </span></a> 
<a name="l33"><span class="ln">33   </span></a> <hr class="ls0"><a name="l34"><span class="ln">34   </span></a>#%% md 
<a name="l35"><span class="ln">35   </span></a>### Importing  All Libraries <hr class="ls0"><a name="l36"><span class="ln">36   </span></a>#%% 
<a name="l37"><span class="ln">37   </span></a></span><span class="s1">import </span><span class="s0">pandas </span><span class="s1">as </span><span class="s0">pd</span>
<a name="l38"><span class="ln">38   </span></a><span class="s1">import </span><span class="s0">numpy </span><span class="s1">as </span><span class="s0">np</span>
<a name="l39"><span class="ln">39   </span></a><span class="s1">import </span><span class="s0">warnings</span>
<a name="l40"><span class="ln">40   </span></a><span class="s1">import </span><span class="s0">matplotlib</span><span class="s2">.</span><span class="s0">pyplot </span><span class="s1">as </span><span class="s0">plt</span>
<a name="l41"><span class="ln">41   </span></a><span class="s1">from </span><span class="s0">sklearn</span><span class="s2">.</span><span class="s0">model_selection </span><span class="s1">import </span><span class="s0">train_test_split</span>
<a name="l42"><span class="ln">42   </span></a><span class="s1">from </span><span class="s0">sklearn</span><span class="s2">.</span><span class="s0">preprocessing </span><span class="s1">import </span><span class="s0">StandardScaler</span>
<a name="l43"><span class="ln">43   </span></a><span class="s1">from </span><span class="s0">sklearn</span><span class="s2">.</span><span class="s0">preprocessing </span><span class="s1">import </span><span class="s0">OneHotEncoder</span>
<a name="l44"><span class="ln">44   </span></a><span class="s1">from </span><span class="s0">sklearn</span><span class="s2">.</span><span class="s0">compose </span><span class="s1">import </span><span class="s0">ColumnTransformer</span>
<a name="l45"><span class="ln">45   </span></a><span class="s1">from </span><span class="s0">sklearn</span><span class="s2">.</span><span class="s0">metrics </span><span class="s1">import </span><span class="s0">r2_score</span><span class="s2">,</span><span class="s0">mean_squared_error</span><span class="s2">,</span><span class="s0">mean_absolute_error</span>
<a name="l46"><span class="ln">46   </span></a><span class="s1">from </span><span class="s0">sklearn</span><span class="s2">.</span><span class="s0">ensemble </span><span class="s1">import </span><span class="s0">RandomForestRegressor</span><span class="s2">,</span><span class="s0">GradientBoostingRegressor</span>
<a name="l47"><span class="ln">47   </span></a><span class="s1">from </span><span class="s0">xgboost </span><span class="s1">import </span><span class="s0">XGBRegressor</span>
<a name="l48"><span class="ln">48   </span></a><span class="s1">from </span><span class="s0">sklearn</span><span class="s2">.</span><span class="s0">pipeline </span><span class="s1">import </span><span class="s0">Pipeline</span>
<a name="l49"><span class="ln">49   </span></a>
<a name="l50"><span class="ln">50   </span></a><span class="s0">warnings</span><span class="s2">.</span><span class="s0">filterwarnings</span><span class="s2">(</span><span class="s3">&quot;ignore&quot;</span><span class="s2">, </span><span class="s0">category</span><span class="s2">=</span><span class="s0">UserWarning</span><span class="s2">)</span>
<a name="l51"><span class="ln">51   </span></a><hr class="ls0"><a name="l52"><span class="ln">52   </span></a><span class="s0">#%% md 
<a name="l53"><span class="ln">53   </span></a>## Importing the dataset 
<a name="l54"><span class="ln">54   </span></a> 
<a name="l55"><span class="ln">55   </span></a>Please refer this link for the DataSet &quot;https://www.kaggle.com/datasets/shubhambathwal/flight-price-prediction?select=Clean_Dataset.csv&quot; 
<a name="l56"><span class="ln">56   </span></a> 
<a name="l57"><span class="ln">57   </span></a>This dataset is already cleaned and uploded on Kaggle website to make Prediction and perform Operation and learn. <hr class="ls0"><a name="l58"><span class="ln">58   </span></a>#%% 
<a name="l59"><span class="ln">59   </span></a>df </span><span class="s2">= </span><span class="s0">pd</span><span class="s2">.</span><span class="s0">read_csv</span><span class="s2">(</span><span class="s3">&quot;data/FlightPredictionDataset.csv&quot;</span><span class="s2">)</span><hr class="ls0"><a name="l60"><span class="ln">60   </span></a><span class="s0">#%% md 
<a name="l61"><span class="ln">61   </span></a></span>
<a name="l62"><span class="ln">62   </span></a><span class="s0">## **Displaying the DataSet** 
<a name="l63"><span class="ln">63   </span></a> 
<a name="l64"><span class="ln">64   </span></a>This DataSet Contains details like 
<a name="l65"><span class="ln">65   </span></a> 
<a name="l66"><span class="ln">66   </span></a>**airline name - Name of the Airlines** 
<a name="l67"><span class="ln">67   </span></a> 
<a name="l68"><span class="ln">68   </span></a>**flight number - Flight Number** 
<a name="l69"><span class="ln">69   </span></a> 
<a name="l70"><span class="ln">70   </span></a> **route - Source and destination city** 
<a name="l71"><span class="ln">71   </span></a> 
<a name="l72"><span class="ln">72   </span></a> **duration - Time taken to travel** 
<a name="l73"><span class="ln">73   </span></a> 
<a name="l74"><span class="ln">74   </span></a> **stops - Any layover in Journey which is also a key feature in Price hike and reduction** 
<a name="l75"><span class="ln">75   </span></a> 
<a name="l76"><span class="ln">76   </span></a> **price - Price of the fight in given journey** 
<a name="l77"><span class="ln">77   </span></a> 
<a name="l78"><span class="ln">78   </span></a> 
<a name="l79"><span class="ln">79   </span></a>**For this my Target Data is Price and  the rest column we use as Features data.** <hr class="ls0"><a name="l80"><span class="ln">80   </span></a>#%% 
<a name="l81"><span class="ln">81   </span></a>df</span><span class="s2">.</span><span class="s0">head</span><span class="s2">()</span>
<a name="l82"><span class="ln">82   </span></a><hr class="ls0"><a name="l83"><span class="ln">83   </span></a><span class="s0">#%% md 
<a name="l84"><span class="ln">84   </span></a>## Data Preprocessing: 
<a name="l85"><span class="ln">85   </span></a> 
<a name="l86"><span class="ln">86   </span></a>Checking for missing values, droping missing values rows. <hr class="ls0"><a name="l87"><span class="ln">87   </span></a>#%% 
<a name="l88"><span class="ln">88   </span></a>print</span><span class="s2">(</span><span class="s0">df</span><span class="s2">.</span><span class="s0">isnull</span><span class="s2">().</span><span class="s0">sum</span><span class="s2">())</span>
<a name="l89"><span class="ln">89   </span></a><span class="s0">df </span><span class="s2">= </span><span class="s0">df</span><span class="s2">.</span><span class="s0">drop</span><span class="s2">(</span><span class="s0">columns</span><span class="s2">=[</span><span class="s3">&quot;Unnamed: 0&quot;</span><span class="s2">])</span>
<a name="l90"><span class="ln">90   </span></a>
<a name="l91"><span class="ln">91   </span></a><span class="s0">df</span><span class="s2">.</span><span class="s0">dropna</span><span class="s2">(</span><span class="s0">inplace</span><span class="s2">=</span><span class="s1">True</span><span class="s2">)</span>
<a name="l92"><span class="ln">92   </span></a>
<a name="l93"><span class="ln">93   </span></a><span class="s0">encoder </span><span class="s2">= </span><span class="s0">OneHotEncoder</span><span class="s2">(</span><span class="s0">handle_unknown</span><span class="s2">=</span><span class="s3">'ignore'</span><span class="s2">, </span><span class="s0">drop</span><span class="s2">=</span><span class="s3">'first'</span><span class="s2">)</span>
<a name="l94"><span class="ln">94   </span></a>
<a name="l95"><span class="ln">95   </span></a><span class="s0">print</span><span class="s2">(</span><span class="s3">&quot;</span><span class="s1">\n</span><span class="s3">Data After Encoding:&quot;</span><span class="s2">)</span>
<a name="l96"><span class="ln">96   </span></a><span class="s0">df</span><span class="s2">.</span><span class="s0">head</span><span class="s2">()</span>
<a name="l97"><span class="ln">97   </span></a><hr class="ls0"><a name="l98"><span class="ln">98   </span></a><span class="s0">#%% md 
<a name="l99"><span class="ln">99   </span></a>## Dividing the table into features and targets 
<a name="l100"><span class="ln">100  </span></a> 
<a name="l101"><span class="ln">101  </span></a>Price is our main target label 
<a name="l102"><span class="ln">102  </span></a> 
<a name="l103"><span class="ln">103  </span></a>Rest all column will be features data 
<a name="l104"><span class="ln">104  </span></a> <hr class="ls0"><a name="l105"><span class="ln">105  </span></a>#%% 
<a name="l106"><span class="ln">106  </span></a>X </span><span class="s2">= </span><span class="s0">df</span><span class="s2">.</span><span class="s0">drop</span><span class="s2">(</span><span class="s3">&quot;price&quot;</span><span class="s2">, </span><span class="s0">axis</span><span class="s2">=</span><span class="s4">1</span><span class="s2">)</span>
<a name="l107"><span class="ln">107  </span></a><span class="s0">y </span><span class="s2">= </span><span class="s0">df</span><span class="s2">[</span><span class="s3">&quot;price&quot;</span><span class="s2">]</span><hr class="ls0"><a name="l108"><span class="ln">108  </span></a><span class="s0">#%% md 
<a name="l109"><span class="ln">109  </span></a>### Identify categorical &amp; numerical features <hr class="ls0"><a name="l110"><span class="ln">110  </span></a>#%% 
<a name="l111"><span class="ln">111  </span></a></span>
<a name="l112"><span class="ln">112  </span></a><span class="s0">cat_col </span><span class="s2">= </span><span class="s0">X</span><span class="s2">.</span><span class="s0">select_dtypes</span><span class="s2">(</span><span class="s0">include</span><span class="s2">=</span><span class="s3">'object'</span><span class="s2">).</span><span class="s0">columns</span>
<a name="l113"><span class="ln">113  </span></a><span class="s0">num_col </span><span class="s2">= </span><span class="s0">X</span><span class="s2">.</span><span class="s0">select_dtypes</span><span class="s2">(</span><span class="s0">exclude</span><span class="s2">=</span><span class="s3">'object'</span><span class="s2">).</span><span class="s0">columns</span>
<a name="l114"><span class="ln">114  </span></a><hr class="ls0"><a name="l115"><span class="ln">115  </span></a><span class="s0">#%% md 
<a name="l116"><span class="ln">116  </span></a>### Preprocessing Pipeline (Encoding + Scaling) 
<a name="l117"><span class="ln">117  </span></a> <hr class="ls0"><a name="l118"><span class="ln">118  </span></a>#%% 
<a name="l119"><span class="ln">119  </span></a></span>
<a name="l120"><span class="ln">120  </span></a>
<a name="l121"><span class="ln">121  </span></a><span class="s0">encoder</span><span class="s2">.</span><span class="s0">fit</span><span class="s2">(</span><span class="s0">X</span><span class="s2">[</span><span class="s0">cat_col</span><span class="s2">])</span>
<a name="l122"><span class="ln">122  </span></a>
<a name="l123"><span class="ln">123  </span></a><span class="s0">preprocess </span><span class="s2">= </span><span class="s0">ColumnTransformer</span><span class="s2">([</span>
<a name="l124"><span class="ln">124  </span></a>    <span class="s2">(</span><span class="s3">'cat'</span><span class="s2">, </span><span class="s0">encoder</span><span class="s2">, </span><span class="s0">cat_col</span><span class="s2">),</span>
<a name="l125"><span class="ln">125  </span></a>    <span class="s2">(</span><span class="s3">'num'</span><span class="s2">, </span><span class="s0">StandardScaler</span><span class="s2">(), </span><span class="s0">num_col</span><span class="s2">)</span>
<a name="l126"><span class="ln">126  </span></a><span class="s2">])</span>
<a name="l127"><span class="ln">127  </span></a><hr class="ls0"><a name="l128"><span class="ln">128  </span></a><span class="s0">#%% md 
<a name="l129"><span class="ln">129  </span></a>**Splitting the DataSet into Train and Test Data to make prediction** 
<a name="l130"><span class="ln">130  </span></a> 
<a name="l131"><span class="ln">131  </span></a>60 % of Data will use as Train data and rest 40 % ,I will be using as Test Data using train_test_split library. This is done due to less time taking on training model. <hr class="ls0"><a name="l132"><span class="ln">132  </span></a>#%% 
<a name="l133"><span class="ln">133  </span></a>X_train</span><span class="s2">, </span><span class="s0">X_test</span><span class="s2">, </span><span class="s0">y_train</span><span class="s2">, </span><span class="s0">y_test </span><span class="s2">= </span><span class="s0">train_test_split</span><span class="s2">(</span><span class="s0">X</span><span class="s2">, </span><span class="s0">y</span><span class="s2">, </span><span class="s0">test_size</span><span class="s2">=</span><span class="s4">0.4</span><span class="s2">, </span><span class="s0">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">)</span><hr class="ls0"><a name="l134"><span class="ln">134  </span></a><span class="s0">#%% md 
<a name="l135"><span class="ln">135  </span></a>**Building Pipeline with Three model for prediction** 
<a name="l136"><span class="ln">136  </span></a> 
<a name="l137"><span class="ln">137  </span></a>These models are tuned to improve prediction accuracy and reduce overfitting. RandomForest uses 300 trees with depth control and feature sampling for stability. GradientBoosting trains 250 sequential learners with lower learning rate for refined improvement. XGBoost is optimized with regularization, subsampling, and boosted rounds for faster, more accurate flight price prediction. 
<a name="l138"><span class="ln">138  </span></a> <hr class="ls0"><a name="l139"><span class="ln">139  </span></a>#%% 
<a name="l140"><span class="ln">140  </span></a>models </span><span class="s2">= {</span>
<a name="l141"><span class="ln">141  </span></a>    <span class="s3">&quot;RandomForest&quot; </span><span class="s2">: </span><span class="s0">RandomForestRegressor</span><span class="s2">(</span>
<a name="l142"><span class="ln">142  </span></a>        <span class="s0">n_estimators</span><span class="s2">=</span><span class="s4">200</span><span class="s2">,</span>
<a name="l143"><span class="ln">143  </span></a>        <span class="s0">max_depth</span><span class="s2">=</span><span class="s4">20</span><span class="s2">,</span>
<a name="l144"><span class="ln">144  </span></a>        <span class="s0">min_samples_split</span><span class="s2">=</span><span class="s4">5</span><span class="s2">,</span>
<a name="l145"><span class="ln">145  </span></a>        <span class="s0">min_samples_leaf</span><span class="s2">=</span><span class="s4">2</span><span class="s2">,</span>
<a name="l146"><span class="ln">146  </span></a>        <span class="s0">max_features</span><span class="s2">=</span><span class="s3">'sqrt'</span><span class="s2">,</span>
<a name="l147"><span class="ln">147  </span></a>        <span class="s0">bootstrap</span><span class="s2">=</span><span class="s1">True</span><span class="s2">,</span>
<a name="l148"><span class="ln">148  </span></a>        <span class="s0">random_state</span><span class="s2">=</span><span class="s4">42</span>
<a name="l149"><span class="ln">149  </span></a>    <span class="s2">),</span>
<a name="l150"><span class="ln">150  </span></a>
<a name="l151"><span class="ln">151  </span></a>    <span class="s3">&quot;GradientBoosting&quot; </span><span class="s2">: </span><span class="s0">GradientBoostingRegressor</span><span class="s2">(</span>
<a name="l152"><span class="ln">152  </span></a>        <span class="s0">n_estimators</span><span class="s2">=</span><span class="s4">250</span><span class="s2">,</span>
<a name="l153"><span class="ln">153  </span></a>        <span class="s0">learning_rate</span><span class="s2">=</span><span class="s4">0.05</span><span class="s2">,</span>
<a name="l154"><span class="ln">154  </span></a>        <span class="s0">max_depth</span><span class="s2">=</span><span class="s4">5</span><span class="s2">,</span>
<a name="l155"><span class="ln">155  </span></a>        <span class="s0">subsample</span><span class="s2">=</span><span class="s4">0.9</span><span class="s2">,</span>
<a name="l156"><span class="ln">156  </span></a>        <span class="s0">min_samples_split</span><span class="s2">=</span><span class="s4">4</span><span class="s2">,</span>
<a name="l157"><span class="ln">157  </span></a>        <span class="s0">min_samples_leaf</span><span class="s2">=</span><span class="s4">2</span><span class="s2">,</span>
<a name="l158"><span class="ln">158  </span></a>        <span class="s0">random_state</span><span class="s2">=</span><span class="s4">42</span>
<a name="l159"><span class="ln">159  </span></a>    <span class="s2">),</span>
<a name="l160"><span class="ln">160  </span></a>
<a name="l161"><span class="ln">161  </span></a>    <span class="s3">&quot;XGBoost&quot; </span><span class="s2">: </span><span class="s0">XGBRegressor</span><span class="s2">(</span>
<a name="l162"><span class="ln">162  </span></a>        <span class="s0">n_estimators</span><span class="s2">=</span><span class="s4">400</span><span class="s2">,</span>
<a name="l163"><span class="ln">163  </span></a>        <span class="s0">learning_rate</span><span class="s2">=</span><span class="s4">0.03</span><span class="s2">,</span>
<a name="l164"><span class="ln">164  </span></a>        <span class="s0">max_depth</span><span class="s2">=</span><span class="s4">7</span><span class="s2">,</span>
<a name="l165"><span class="ln">165  </span></a>        <span class="s0">colsample_bytree</span><span class="s2">=</span><span class="s4">0.8</span><span class="s2">,</span>
<a name="l166"><span class="ln">166  </span></a>        <span class="s0">subsample</span><span class="s2">=</span><span class="s4">0.85</span><span class="s2">,</span>
<a name="l167"><span class="ln">167  </span></a>        <span class="s0">reg_lambda</span><span class="s2">=</span><span class="s4">2</span><span class="s2">,</span>
<a name="l168"><span class="ln">168  </span></a>        <span class="s0">reg_alpha</span><span class="s2">=</span><span class="s4">1</span><span class="s2">,</span>
<a name="l169"><span class="ln">169  </span></a>        <span class="s0">gamma</span><span class="s2">=</span><span class="s4">0.2</span><span class="s2">,</span>
<a name="l170"><span class="ln">170  </span></a>        <span class="s0">random_state</span><span class="s2">=</span><span class="s4">42</span><span class="s2">,</span>
<a name="l171"><span class="ln">171  </span></a>        <span class="s0">objective</span><span class="s2">=</span><span class="s3">'reg:squarederror'</span>
<a name="l172"><span class="ln">172  </span></a>    <span class="s2">)</span>
<a name="l173"><span class="ln">173  </span></a><span class="s2">}</span>
<a name="l174"><span class="ln">174  </span></a><hr class="ls0"><a name="l175"><span class="ln">175  </span></a><span class="s0">#%% md 
<a name="l176"><span class="ln">176  </span></a>**Predicting the result** 
<a name="l177"><span class="ln">177  </span></a> 
<a name="l178"><span class="ln">178  </span></a>This loop trains and evaluates all models stored in the models results. For each model, a pipeline is created combining preprocessing and regression. The model is trained using the training dataset and then predicts prices on the test set. Performance is measured using RÂ², RMSE, and MAE, which reflect accuracy and error rate. The results of each model are stored in a dictionary and printed for comparison, helping identify which model performs best for flight price prediction. <hr class="ls0"><a name="l179"><span class="ln">179  </span></a>#%% 
<a name="l180"><span class="ln">180  </span></a>results </span><span class="s2">= {}</span>
<a name="l181"><span class="ln">181  </span></a><span class="s1">for </span><span class="s0">name</span><span class="s2">, </span><span class="s0">model </span><span class="s1">in </span><span class="s0">models</span><span class="s2">.</span><span class="s0">items</span><span class="s2">():</span>
<a name="l182"><span class="ln">182  </span></a>    <span class="s0">pipeline </span><span class="s2">= </span><span class="s0">Pipeline</span><span class="s2">(</span><span class="s0">steps</span><span class="s2">=[(</span><span class="s3">&quot;preprocessing&quot;</span><span class="s2">, </span><span class="s0">preprocess</span><span class="s2">),</span>
<a name="l183"><span class="ln">183  </span></a>                               <span class="s2">(</span><span class="s3">&quot;model&quot;</span><span class="s2">, </span><span class="s0">model</span><span class="s2">)])</span>
<a name="l184"><span class="ln">184  </span></a>
<a name="l185"><span class="ln">185  </span></a>    <span class="s0">pipeline</span><span class="s2">.</span><span class="s0">fit</span><span class="s2">(</span><span class="s0">X_train</span><span class="s2">, </span><span class="s0">y_train</span><span class="s2">)</span>
<a name="l186"><span class="ln">186  </span></a>    <span class="s0">y_pred </span><span class="s2">= </span><span class="s0">pipeline</span><span class="s2">.</span><span class="s0">predict</span><span class="s2">(</span><span class="s0">X_test</span><span class="s2">)</span>
<a name="l187"><span class="ln">187  </span></a>
<a name="l188"><span class="ln">188  </span></a>    <span class="s0">r2 </span><span class="s2">= </span><span class="s0">r2_score</span><span class="s2">(</span><span class="s0">y_test</span><span class="s2">, </span><span class="s0">y_pred</span><span class="s2">)</span>
<a name="l189"><span class="ln">189  </span></a>    <span class="s0">rmse </span><span class="s2">= </span><span class="s0">np</span><span class="s2">.</span><span class="s0">sqrt</span><span class="s2">(</span><span class="s0">mean_squared_error</span><span class="s2">(</span><span class="s0">y_test</span><span class="s2">, </span><span class="s0">y_pred</span><span class="s2">))</span>
<a name="l190"><span class="ln">190  </span></a>    <span class="s0">mae </span><span class="s2">= </span><span class="s0">mean_absolute_error</span><span class="s2">(</span><span class="s0">y_test</span><span class="s2">, </span><span class="s0">y_pred</span><span class="s2">)</span>
<a name="l191"><span class="ln">191  </span></a>
<a name="l192"><span class="ln">192  </span></a>    <span class="s0">results</span><span class="s2">[</span><span class="s0">name</span><span class="s2">] = [</span><span class="s0">r2</span><span class="s2">, </span><span class="s0">rmse</span><span class="s2">, </span><span class="s0">mae</span><span class="s2">]</span>
<a name="l193"><span class="ln">193  </span></a>    <span class="s0">print</span><span class="s2">(</span><span class="s3">f&quot;</span><span class="s1">\n {</span><span class="s0">name</span><span class="s1">} </span><span class="s3">Results:&quot;</span><span class="s2">)</span>
<a name="l194"><span class="ln">194  </span></a>    <span class="s0">print</span><span class="s2">(</span><span class="s3">&quot;R2 Score     :&quot;</span><span class="s2">, </span><span class="s0">r2</span><span class="s2">)</span>
<a name="l195"><span class="ln">195  </span></a>    <span class="s0">print</span><span class="s2">(</span><span class="s3">&quot;RMSE         :&quot;</span><span class="s2">, </span><span class="s0">rmse</span><span class="s2">)</span>
<a name="l196"><span class="ln">196  </span></a>    <span class="s0">print</span><span class="s2">(</span><span class="s3">&quot;MAE          :&quot;</span><span class="s2">, </span><span class="s0">mae</span><span class="s2">)</span><hr class="ls0"><a name="l197"><span class="ln">197  </span></a><span class="s0">#%% md 
<a name="l198"><span class="ln">198  </span></a>Predicting the best model and Comparison 
<a name="l199"><span class="ln">199  </span></a> 
<a name="l200"><span class="ln">200  </span></a>This block gives the best-performing model from the results by comparing RÂ² scores. The function identifies the model with the highest RÂ² value, indicating the most accurate prediction. The results of all models are then organized into a DataFrame for clear tabular comparison. The table displays RÂ² Score, RMSE, and MAE for each algorithm, making it easy to analyze performance differences. Finally, the comparison result is printed, helping choose the most suitable model for flight price prediction. <hr class="ls0"><a name="l201"><span class="ln">201  </span></a>#%% 
<a name="l202"><span class="ln">202  </span></a>best_model_name </span><span class="s2">= </span><span class="s0">max</span><span class="s2">(</span><span class="s0">results</span><span class="s2">, </span><span class="s0">key</span><span class="s2">=</span><span class="s1">lambda </span><span class="s0">x</span><span class="s2">: </span><span class="s0">results</span><span class="s2">[</span><span class="s0">x</span><span class="s2">][</span><span class="s4">0</span><span class="s2">])</span>
<a name="l203"><span class="ln">203  </span></a><span class="s0">print</span><span class="s2">(</span><span class="s3">f&quot;</span><span class="s1">\n</span><span class="s3">ðŸš€ Best Performing Model is: </span><span class="s1">{</span><span class="s0">best_model_name</span><span class="s1">}</span><span class="s3">&quot;</span><span class="s2">)</span>
<a name="l204"><span class="ln">204  </span></a>
<a name="l205"><span class="ln">205  </span></a><span class="s0">results_df </span><span class="s2">= </span><span class="s0">pd</span><span class="s2">.</span><span class="s0">DataFrame</span><span class="s2">(</span><span class="s0">results</span><span class="s2">, </span><span class="s0">index</span><span class="s2">=[</span><span class="s3">&quot;R2 Score&quot;</span><span class="s2">,</span><span class="s3">&quot;RMSE&quot;</span><span class="s2">,</span><span class="s3">&quot;MAE&quot;</span><span class="s2">]).</span><span class="s0">T</span>
<a name="l206"><span class="ln">206  </span></a><span class="s0">print</span><span class="s2">(</span><span class="s3">&quot;</span><span class="s1">\n</span><span class="s3">ðŸ”¥ Model Performance Comparison:</span><span class="s1">\n</span><span class="s3">&quot;</span><span class="s2">)</span>
<a name="l207"><span class="ln">207  </span></a>
<a name="l208"><span class="ln">208  </span></a>
<a name="l209"><span class="ln">209  </span></a><span class="s0">print</span><span class="s2">(</span><span class="s0">results_df</span><span class="s2">)</span><hr class="ls0"><a name="l210"><span class="ln">210  </span></a><span class="s0">#%% md 
<a name="l211"><span class="ln">211  </span></a>Now pLotting the performance metrics of all trained models using a bar graph. The results_df.plot() command plots the RÂ², RMSE, and MAE values for each model, with a figure size of 10Ã—5 for better visualization. The graph is given a title &quot;Model Performance Comparison&quot; and the y-axis is labeled Score. Finally, plt.show() displays the bar chart, helping compare model performance visually and quickly identify which model performs best. <hr class="ls0"><a name="l212"><span class="ln">212  </span></a>#%% 
<a name="l213"><span class="ln">213  </span></a>plt</span><span class="s2">.</span><span class="s0">figure</span><span class="s2">(</span><span class="s0">figsize</span><span class="s2">=(</span><span class="s4">10</span><span class="s2">,</span><span class="s4">5</span><span class="s2">))</span>
<a name="l214"><span class="ln">214  </span></a><span class="s0">results_df</span><span class="s2">.</span><span class="s0">plot</span><span class="s2">(</span><span class="s0">kind</span><span class="s2">=</span><span class="s3">&quot;bar&quot;</span><span class="s2">, </span><span class="s0">figsize</span><span class="s2">=(</span><span class="s4">10</span><span class="s2">,</span><span class="s4">5</span><span class="s2">))</span>
<a name="l215"><span class="ln">215  </span></a><span class="s0">plt</span><span class="s2">.</span><span class="s0">title</span><span class="s2">(</span><span class="s3">&quot;Model Performance Comparison&quot;</span><span class="s2">)</span>
<a name="l216"><span class="ln">216  </span></a><span class="s0">plt</span><span class="s2">.</span><span class="s0">xlabel</span><span class="s2">(</span><span class="s3">&quot;Models&quot;</span><span class="s2">)</span>
<a name="l217"><span class="ln">217  </span></a><span class="s0">plt</span><span class="s2">.</span><span class="s0">ylabel</span><span class="s2">(</span><span class="s3">&quot;Score Value&quot;</span><span class="s2">)</span>
<a name="l218"><span class="ln">218  </span></a><span class="s0">plt</span><span class="s2">.</span><span class="s0">grid</span><span class="s2">(</span><span class="s1">True</span><span class="s2">)</span>
<a name="l219"><span class="ln">219  </span></a><span class="s0">plt</span><span class="s2">.</span><span class="s0">show</span><span class="s2">()</span><hr class="ls0"><a name="l220"><span class="ln">220  </span></a><span class="s0">#%% md 
<a name="l221"><span class="ln">221  </span></a>## Retrain the best model to predict the best price for a example set of airlines data <hr class="ls0"><a name="l222"><span class="ln">222  </span></a>#%% 
<a name="l223"><span class="ln">223  </span></a></span>
<a name="l224"><span class="ln">224  </span></a><span class="s0">best_model </span><span class="s2">= </span><span class="s0">models</span><span class="s2">[</span><span class="s0">best_model_name</span><span class="s2">]</span>
<a name="l225"><span class="ln">225  </span></a>
<a name="l226"><span class="ln">226  </span></a><span class="s0">final_pipeline </span><span class="s2">= </span><span class="s0">Pipeline</span><span class="s2">(</span><span class="s0">steps</span><span class="s2">=[</span>
<a name="l227"><span class="ln">227  </span></a>    <span class="s2">(</span><span class="s3">&quot;preprocessing&quot;</span><span class="s2">, </span><span class="s0">preprocess</span><span class="s2">),</span>
<a name="l228"><span class="ln">228  </span></a>    <span class="s2">(</span><span class="s3">&quot;model&quot;</span><span class="s2">, </span><span class="s0">best_model</span><span class="s2">)</span>
<a name="l229"><span class="ln">229  </span></a><span class="s2">])</span>
<a name="l230"><span class="ln">230  </span></a>
<a name="l231"><span class="ln">231  </span></a><span class="s0">final_pipeline</span><span class="s2">.</span><span class="s0">fit</span><span class="s2">(</span><span class="s0">X</span><span class="s2">, </span><span class="s0">y</span><span class="s2">)</span>
<a name="l232"><span class="ln">232  </span></a><span class="s0">print</span><span class="s2">(</span><span class="s3">f&quot;</span><span class="s1">\n</span><span class="s3">ðŸ’¡ Final Model Ready: </span><span class="s1">{</span><span class="s0">best_model_name</span><span class="s1">}</span><span class="s3">&quot;</span><span class="s2">)</span>
<a name="l233"><span class="ln">233  </span></a><hr class="ls0"><a name="l234"><span class="ln">234  </span></a><span class="s0">#%% md 
<a name="l235"><span class="ln">235  </span></a>## checking feature columns used in training for setting an example <hr class="ls0"><a name="l236"><span class="ln">236  </span></a>#%% 
<a name="l237"><span class="ln">237  </span></a></span>
<a name="l238"><span class="ln">238  </span></a><span class="s0">print</span><span class="s2">(</span><span class="s3">&quot;</span><span class="s1">\n</span><span class="s3">Model Expecting Columns:</span><span class="s1">\n</span><span class="s3">&quot;</span><span class="s2">, </span><span class="s0">X</span><span class="s2">.</span><span class="s0">columns</span><span class="s2">)</span>
<a name="l239"><span class="ln">239  </span></a><hr class="ls0"><a name="l240"><span class="ln">240  </span></a><span class="s0">#%% md 
<a name="l241"><span class="ln">241  </span></a>This Example set an experiment to get the price value of fight operating with features and predicting the price. <hr class="ls0"><a name="l242"><span class="ln">242  </span></a>#%% 
<a name="l243"><span class="ln">243  </span></a></span>
<a name="l244"><span class="ln">244  </span></a><span class="s0">sample </span><span class="s2">= </span><span class="s0">pd</span><span class="s2">.</span><span class="s0">DataFrame</span><span class="s2">([{</span>
<a name="l245"><span class="ln">245  </span></a>    <span class="s3">&quot;airline&quot;</span><span class="s2">: </span><span class="s3">&quot;IndiGo&quot;</span><span class="s2">,</span>
<a name="l246"><span class="ln">246  </span></a>    <span class="s3">&quot;flight&quot;</span><span class="s2">: </span><span class="s3">&quot;6E-973&quot;</span><span class="s2">,</span>
<a name="l247"><span class="ln">247  </span></a>    <span class="s3">&quot;source_city&quot;</span><span class="s2">: </span><span class="s3">&quot;Delhi&quot;</span><span class="s2">,</span>
<a name="l248"><span class="ln">248  </span></a>    <span class="s3">&quot;departure_time&quot;</span><span class="s2">: </span><span class="s3">&quot;Morning&quot;</span><span class="s2">,</span>
<a name="l249"><span class="ln">249  </span></a>    <span class="s3">&quot;stops&quot;</span><span class="s2">: </span><span class="s3">&quot;one&quot;</span><span class="s2">,</span>
<a name="l250"><span class="ln">250  </span></a>    <span class="s3">&quot;arrival_time&quot;</span><span class="s2">: </span><span class="s3">&quot;Night&quot;</span><span class="s2">,</span>
<a name="l251"><span class="ln">251  </span></a>    <span class="s3">&quot;destination_city&quot;</span><span class="s2">: </span><span class="s3">&quot;Mumbai&quot;</span><span class="s2">,</span>
<a name="l252"><span class="ln">252  </span></a>    <span class="s3">&quot;class&quot;</span><span class="s2">: </span><span class="s3">&quot;Economy&quot;</span><span class="s2">,</span>
<a name="l253"><span class="ln">253  </span></a>    <span class="s3">&quot;duration&quot;</span><span class="s2">: </span><span class="s4">2.5</span><span class="s2">,</span>
<a name="l254"><span class="ln">254  </span></a>    <span class="s3">&quot;days_left&quot;</span><span class="s2">: </span><span class="s4">20</span>
<a name="l255"><span class="ln">255  </span></a><span class="s2">}])</span>
<a name="l256"><span class="ln">256  </span></a>
<a name="l257"><span class="ln">257  </span></a><span class="s0">pred </span><span class="s2">= </span><span class="s0">final_pipeline</span><span class="s2">.</span><span class="s0">predict</span><span class="s2">(</span><span class="s0">sample</span><span class="s2">)</span>
<a name="l258"><span class="ln">258  </span></a><span class="s0">print</span><span class="s2">(</span><span class="s3">f&quot;</span><span class="s1">\n </span><span class="s3">Predicted Ticket Price: â‚¹ </span><span class="s1">{</span><span class="s0">round</span><span class="s2">(</span><span class="s0">pred</span><span class="s2">[</span><span class="s4">0</span><span class="s2">],</span><span class="s4">2</span><span class="s2">)</span><span class="s1">}</span><span class="s3">&quot;</span><span class="s2">)</span><hr class="ls0"><a name="l259"><span class="ln">259  </span></a><span class="s0">#%% md 
<a name="l260"><span class="ln">260  </span></a>## **Conclusion:** 
<a name="l261"><span class="ln">261  </span></a> 
<a name="l262"><span class="ln">262  </span></a>In this project, I have trained three model pipeline to make prediction of flight price and also predict price for a manual given sample Data with the best model (**XGBoost**). 
<a name="l263"><span class="ln">263  </span></a>In this project i have used three models: 
<a name="l264"><span class="ln">264  </span></a>**Gradient Boosting Regressor** 
<a name="l265"><span class="ln">265  </span></a> 
<a name="l266"><span class="ln">266  </span></a>**XGBoost** 
<a name="l267"><span class="ln">267  </span></a> 
<a name="l268"><span class="ln">268  </span></a>**Random Forest Regressor** 
<a name="l269"><span class="ln">269  </span></a> 
<a name="l270"><span class="ln">270  </span></a>which give R2 Score of 67%, 96%, 97%. So This conclude the best model for this dataset is XGBoost with 97% of accuracy with the help of **Hyperparameter Tuning**. 
<a name="l271"><span class="ln">271  </span></a> 
<a name="l272"><span class="ln">272  </span></a>This percentage of accuracy make this model to efficient to companies to predict the price of Airline according to Flight details as features table. This will help them to grow business and they can plan offers 
<a name="l273"><span class="ln">273  </span></a>and discounts. 
<a name="l274"><span class="ln">274  </span></a> 
<a name="l275"><span class="ln">275  </span></a>For Model would definitely implemented in many online Airline Ticket Websites to predict the future flights price according to previous DataSets. We just need to upload current dataset and guve a sample example to forecast the price the Flight 
<a name="l276"><span class="ln">276  </span></a> 
<a name="l277"><span class="ln">277  </span></a> 
<a name="l278"><span class="ln">278  </span></a>Thanks for your Attentions. 
<a name="l279"><span class="ln">279  </span></a> 
<a name="l280"><span class="ln">280  </span></a> 
<a name="l281"><span class="ln">281  </span></a>Name       -  Aniket Sonu 
<a name="l282"><span class="ln">282  </span></a> 
<a name="l283"><span class="ln">283  </span></a>Student ID -  GH1048274 
<a name="l284"><span class="ln">284  </span></a> 
<a name="l285"><span class="ln">285  </span></a>Email Id   -  Aniket.Sonu@gisma-student.com <hr class="ls0"><a name="l286"><span class="ln">286  </span></a>#%% 
<a name="l287"><span class="ln">287  </span></a></span></pre>
</body>
</html>